% this file is called up by thesis.tex
% content in this file will be fed into the main document

%: ----------------------- name of chapter  -------------------------
\chapter{Concept} % top level followed by section, subsection
As indicated in similar research it's very attractive to use additional data to enhance reconstruction and reduce ambiguity in finding correct solution of 3D reconstruction. Additional camera or model information help to implement faster, more stable and robust algorithms. This thesis will show how prior knowledge of rotation or translation acquired via mobile sensor fusion can be used to enhance process of 3D reconstruction from series images. When it comes to relaying on hand-held smartphones, collected sensor data are very noisy. This thesis, how even noisy informations can be used in struction reconstraction processes. Initially only camera rotation estimation was supposed to be used in the scope of this mater thesis. However first trials of reconstruction proved to be not sufficient enough and additional rotation error matrix estimations were proposed.
From analysis of theory and related works it seems that both epipolar equations and pose estimation techniques can be improved with additional rotation and translation information data.  Author of this thesis proposes environment, where user can decide what type of stargy to use. In terms of initialization of 3D cloud point reconstraction can be made using: 

\section{Requirements}
Proposed methodology needs as the input series of images with additional information about position of the camera - euclidan rotation and optionally translation. Usage of smartphone is actually not necessary. Any camera with SensorFusioned accelerometer and gyroscope(magnotometer is actually optional and as discussed in [TODO] has its advantages and disadvantages) capable of rotation and translation estimation can be used. Internal camera parameters need to be calculated before reconstruction process is started. Additional sensor data doesn't have to be very accurate. Noisy external camera parameters stil can be successfully used in order to enhance reconstruction process.
\section{Enhancing epipolar geometry equations - rotation enhancments}
Initial pair reconstruction step is very important and needs to be accurate for other
Taking standard fundamental geometry equation and relative camera based system ($P = \begin{bmatrix}I |0\end{bmatrix}, P' = \begin{bmatrix}R|t\end{bmatrix}$) we can note that:
\begin{equation} \label{eq:relativeFundamntal}
{x}_{'}^{T} * K^{-T} * \begin{bmatrix}T\end{bmatrix}_{x} * R * K^{-1} * x = 0
\end{equation}
It is can be written that:
\begin{equation} \label{eq:skewTranslation}
\begin{bmatrix}T\end{bmatrix}_{x} = 
\begin{bmatrix*}[c]
 0 & -t_{z} & t_{y}\\
 t_{z} & 0 & -t_{x}\\
-t_{y} & t_{x} & 0 
\end{bmatrix*} 
where T = \begin{bmatrix}t_{x},t_{y},t_{z}\end{bmatrix}
\end{equation}
As we were discussing both rotation can be distorted with noise. This can be written as:
\begin{equation} \label{eq:Rerror}
R = R_{error} * R_{init} 
\end{equation}
where $R_{init}$ is rotation matrix from measured angles and $R_{error}$ is rotation matrix of angles errors.
Looking at this from different point of view \ref{eq:Rerror} can be interpreted as multipling two rotations matrix: 
One estimated, but close to local optimum initial rotation matrix and second one correcting noise error rotation matrix. 
Basic idea of algorithm proposed in this thesis is instead of R calculation, which as described in [reference] can be acquired from Essential matrix SVD decomposition, $R_{error}$ will be estimated. In the end \ref{eq:relativeFundamntal} can be rewritten in form:
\begin{equation} \label{eq:relativeFundamntalEnhanced}
{x}_{'}^{T} * K^{-T} * \begin{bmatrix}T\end{bmatrix}_{x} * R_{error} * R_{init} * K^{-1} * x = 0
\end{equation}
Having:
\begin{equation} \label{eq:leftRelative}
\begin{array}{lcl}
h_{'}^{T} &=& {x}_{'}^{T} * K^{-T} \\
h &=& R_{init} * K^{-1} * x \\
G &=& \begin{bmatrix}T\end{bmatrix}_{x} * R_{error} \\
\end{array}
\end{equation}

With such notation one can notice that
\begin{equation} \label{eq:alternativeEnhancedEquation}
{h}_{'}^{T} * G * h = 0
\end{equation}
quite resembles both standard fundamental and essential equation [reference]. Of cource $h_{'}$ and h are both homogenous. From analysis it's known that G has 6DOF: 3 due to unknown translation and 3 due to unknown correction angles. From theory such matrix can be resolved for instance by both 5 and 8-point algorithms. So basicly standard fundamental and essential equation solvers can be used in order to retrieve both $\begin{bmatrix}T\end{bmatrix}_{x}$ and $R_{error}$ in order to resolve some common problems in retrieving correct solution and improve accuracy. 
In the end estimated $R_{error}$ and calculated $R_{init}$ can be multiplied to retrieve new rotation R (\ref{eq:Rerror}).
Also to reduce error estimation using Rodigues parametrization, when the angles are small(and they indeed are because only small error is present in sensor data) we can note that $R_{error}$ in fact is more or less equals to:
\begin{equation}
R_{error} \cong 
\begin{bmatrix*}[c]
 1& -w_{z}  &w_{y}\\ 
 w_{z} &1  & -w_{x}\\
  -w_{y}&  w_{x}&1
\end{bmatrix*}
\end{equation} 
[Refernece to Hartley]. It can be used when decomposing G to ensure proper decomposition. What's more in normal situation in case of both these algorithms we have to decompose recovered matrix to both relative rotation and translation. However we normally have to deal with small ambiguity and check for instance by initial triangulation, which R and T use. Using this Rodriguez representation, we can reduce 4 solution test cases to 2 possibly solutions test-case.
\subsection{Alternative 3-point algorithm for translation finding}
Starting \ref{eq:alternativeEnhancedEquation} it can be written that:
\begin{equation} \label{eq:alternative3point}
{x}_{'}^{T} * K^{-T} * \begin{bmatrix*}[c]
 0 & -t_{z} & t_{y}\\
 t_{z} & 0 & -t_{x}\\
-t_{y} & t_{x} & 0 
\end{bmatrix*} * R * K^{-1} * x = 0
\end{equation}
Having:
\begin{equation} \label{eq:leftRelative}
\begin{array}{lcl}
h_{'}^{T} &=& {x}_{'}^{T} * K^{-T} \\
h &=& K^{-1} * x \\
\end{array}
\end{equation}
\begin{equation} \label{eq:alternative3point}
\begin{bmatrix*}[c]
h_{'1} & h_{'2} & h_{'3}
\end{bmatrix*}
* \begin{bmatrix*}[c]
 0 & -t_{z} & t_{y}\\
 t_{z} & 0 & -t_{x}\\
-t_{y} & t_{x} & 0 
\end{bmatrix*} 
* \begin{bmatrix*}[c]
h_{1} \\
h_{2} \\
h_{3}
\end{bmatrix*}
= 0
\end{equation}
and multiplying it we will end up with
\begin{equation} \label{eq:alternative3point}
h_{1}*h_{'2}*t_{z} - h_{1}*h_{'3}*t_{y} - h_{2}*h_{'1}*t_{z} + h_{2}*h_{'3}*t_{x} + h_{3}*h_{'1}*t_{y} - h_{3}*h_{'2}*t_{x}
= 0
\end{equation}
what can be grouped:
\begin{equation}
t_{x} * (h_{2}*h_{'3} - h_{3}*h_{'2}) + t_{y} * (h_{3}*h_{'1} - h_{1}*h_{'3}) + t_{z} * (h_{1}*h_{'2} - h_{2}*h_{'1}) = 0
\end{equation}
rewritten as:
\begin{equation} \label{eq:translation3point}
\begin{bmatrix*}[c]
t_{x} &
t_{y} &
t_{z}
\end{bmatrix*} * \begin{bmatrix*}[c]
(h_{2}*h_{'3} - h_{3}*h_{'2}) \\ 
(h_{3}*h_{'1} - h_{1}*h_{'3}) \\
(h_{1}*h_{'2} - h_{2}*h_{'1}) 
\end{bmatrix*} 
= 0
\end{equation}
and solved for instance with SVD with only 3 points. This is very attractive way of reconstracting images from only 3 points especially in terms of speed. Overall accuracy strictly relies on precise measuerments of camera orientation.
\section{Pose estimation}
Different approaches to continous multiview 3D reconstruction were discussed. This research main goal was to make it more accurate and faster. That is way it focuses on pose estimation instead of homographies merging. This is also good in terms of keeping scale in between next image analysis. For any point in image following condition is kept:
\begin{equation} \label{eq:projectionEquation}
 x = P * X
\end{equation}
where x is homogenous image point (x , y , 1) and X homogenous 3D  point (X , Y , Z , 1). Of course 
\begin{equation} \label{eq:projectionEquation}
 P = K * \begin{bmatrix}R\mid t\end{bmatrix}
\end{equation}
\subsection{Known rotations \& translations}
In situation were rotations and translations of cameras are known no aditional calculations are needed. Both rotation and translation of the camera can be estimated from sensors. Such situation is interesting, because there is already everything needed for triangulation of points. To resolve inaccuracy of especially translation measurements standard Bundle Adjustment methods can be used in order to refine reconstruction results.
\subsection{Rotation enhancements}
Using similar thinking as in previous section[ref] we can note that:

\begin{equation} \label{eq:projectionRotError1}
\begin{array}{rcl}
 x & = & K * \begin{bmatrix}Rinit + dR\mid t\end{bmatrix} * X \\
 x & = & K * \begin{bmatrix}Rinit\mid 0\end{bmatrix} * X + K * \begin{bmatrix}dR\mid t\end{bmatrix} * X \\
 x - K * \begin{bmatrix}Rinit\mid 0\end{bmatrix} & = & K * \begin{bmatrix}dR\mid t\end{bmatrix} * X
\end{array}
\end{equation}
Substituting $x_{m} = x - K * \begin{bmatrix}Rinit\mid 0\end{bmatrix}$ we get: 
\begin{equation} \label{eq:projectionRotError2}
x_{m} = K * \begin{bmatrix}dR\mid t\end{bmatrix} * X
\end{equation}
This can be solved using normal PNP calculating algorithms. It's known that orientation estimation is more accurate than translation estimation using SensorFusion and this approach allows very accurate calculation of rotation error matrix dR and translation t, which keeps the scale of initially reconstructed points cloud.
\subsection{Rotation \& translation enhancements}
Similar to \ref{eq:projectionRotError1}:
\begin{equation} \label{eq:projectionRotError3}
\begin{array}{rcl}
 x & = & K * \begin{bmatrix}Rinit + dR\mid Tinit + dt\end{bmatrix} * X \\
 x & = & K * \begin{bmatrix}Rinit\mid Tinit\end{bmatrix} * X + K * \begin{bmatrix}dR\mid dt\end{bmatrix} * X \\
 x - K * \begin{bmatrix}Rinit\mid Tinit\end{bmatrix} & = & K * \begin{bmatrix}dR\mid dt\end{bmatrix} * X
\end{array}
\end{equation}
end in the end by Substituting $x_{n} = x - K * \begin{bmatrix}Rinit\mid Tinit\end{bmatrix}$ we get: 
\begin{equation} \label{eq:projectionRotError4}
x_{n} = K * \begin{bmatrix}dR\mid dt\end{bmatrix} * X
\end{equation}
We can note that when initial solution is already known, the problems begins to focus on refining pose estimation instead of searching for it.
\section{Reconstruction process strategy}
Finally proposed reconstruction environment, where initial estimates of rotation 
%TODO zrobić lepszy styl
\begin{enumerate} 
\item Known rotatations and translations - relative poses are calculated from sensor data - euclidan reconstruction
\item Known rotations - Alternative 3-point algorithm for translation finding or enhanced fundamental/essential
\item Noisy rotation - enhanced fundamental/essential for dR and translation
\item No known extrisinc parameters - standard fundamental/essential for R and Translation
\end{enumerate}
Later one new images are analized in comparison to previous one to enrich initial cloud point with new points. It's only necessery to keep track of each 3D cloud point corresponding 2D positions in images. In terms of Pose Estimation following methodologies can be used:
\begin{enumerate}
\item Known rotatation and translations - no additional calculations, just triangulation - euclidan reconstruction
\item Known rotation - looking for relative translation by backProjection optimisations
\item Noisy rotation - looking for dR and translation by backProjection optimisations
\item No known extrisinc parameters - standard pose estimation
\end{enumerate}
Of cource in all of this steps it's really important to have as minimum outliers as possible. All of this methods are pretty good in terms of removing outliers, espiecially when connected with RANSAC algorithm.

 
 
%TODO
%In this thesis I will propose different approaches, where reconstruction process can be dymacily adapted in terms of accuracy and speed. There are few approaches:
%Noisy rotation -> feature finding and outliers removal -> dR and translation from essential decomposition or pose estimation -> with or without BA -> better accuracy and robustness
%Noisy rotations and translations -> feature finding and outliers removal -> with or without BA -> super convergance
%Noisy rotations and translations -> feature finding and outliers removal -> dR and dT estimation from modified essential decomposition -> with or without BA -> better accuracy and robustness
%Noisy rotation -> feature finding and outliers removal -> translation from essential decomposition or pose estimation -> with or without BA -> better accuracy and robustness


% ---------------------------------------------------------------------------
%: ----------------------- end of thesis sub-document ------------------------
% ---------------------------------------------------------------------------

