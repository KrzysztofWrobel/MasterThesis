% this file is called up by thesis.tex
% content in this file will be fed into the main document

%: ----------------------- name of chapter  -------------------------
\chapter{Concept} % top level followed by section, subsection
As indicated in a similar research (Chapter 3), it is very attractive to use additional data to enhance reconstruction and reduce ambiguity in finding correct solution for 3D reconstruction. Additional camera or model information help to implement faster, more stable and robust algorithms. This thesis will show how the prior knowledge of rotation or translation acquired via mobile sensor fusion can be used to enhance process of 3D reconstruction from a series of images. When it comes to relying on hand-held smartphones, the collected sensor data are very noisy. This thesis shows how even noisy information can be used in the reconstruction processes. Initially, only the camera rotation estimation was supposed to be used within the scope of this thesis. However, the first attempts to perform reconstruction proved it to be not sufficient and additional rotation error matrix estimations were developed.
It follows from the analysis of the theory and related works that both epipolar equations and pose estimation techniques can be improved by additional rotation and translation information data.  Author of this thesis proposes the use of an environment, where a user can decide what type of strategy to use.
\section{Requirements}
The proposed methodology needs an input in the form of a series of images with additional information about the position of the camera - the euclidean rotation and, optionally, translation. The use of smartphone is not necessary; any camera with sensor-fusioned accelerometer and gyroscope (magnetometer and the use thereof is optional, as discussed in \cite{website:androidSensorOverview}, has both advantages and disadvantages), capable of performing the rotation and translation estimation, can be used.The internal camera parameters need to be calculated before the reconstruction process commences. Additional sensor data need not be fully accurate. Noisy external camera parameters can still be successfully used for enhancing the reconstruction process.
\section{Enhancing epipolar geometry equations with initial rotation matrix} \label{sec:EpipolarEquation}
The initial pair reconstruction step is of utmost importance and needs to be accurate in order to let the other images calculate relative position based on the initially reconstructed 3D cloud points.
Analysis of the standard fundamental geometry equation and the relative camera based system ($P = \begin{bmatrix}I |0\end{bmatrix}, P' = \begin{bmatrix}R|t\end{bmatrix}$) results in the following:
\begin{equation} \label{eq:relativeFundamntal}
{x}_{'}^{T} * K^{-T} * \begin{bmatrix}T\end{bmatrix}_{x} * R * K^{-1} * x = 0
\end{equation}
It can also be noted that:
\begin{equation} \label{eq:skewTranslation}
\begin{bmatrix}T\end{bmatrix}_{x} = 
\begin{bmatrix*}[c]
 0 & -t_{z} & t_{y}\\
 t_{z} & 0 & -t_{x}\\
-t_{y} & t_{x} & 0 
\end{bmatrix*} 
where T = \begin{bmatrix}t_{x},t_{y},t_{z}\end{bmatrix}
\end{equation}
As already discussed, rotation can be distorted with noise. This can be written down as:
\begin{equation} \label{eq:Rerror}
R = R_{error} * R_{init} 
\end{equation}
where $R_{init}$ is initial rotation matrix constructed from the measured angles and $R_{error}$ is rotation error matrix.
Looking at this from a different point of view equation \ref{eq:Rerror} one can interpret it as the multiplication of the two rotation matrices: 
one estimated initial rotation matrix (but close to local optimum) and the second one responsible for correction of noise error. 
Instead of on the relative rotation matrix calculation, the primary idea of the algorithm proposed in this thesis is based on the entire rotation matrix calculation, which can be acquired from the essential matrix SVD decomposition, where only the rotation $R_{error}$ can be estimated. Eventually, equation \ref{eq:relativeFundamntal} can be rewritten as:
\begin{equation} \label{eq:relativeFundamntalEnhanced}
{x}_{'}^{T} * K^{-T} * \begin{bmatrix}T\end{bmatrix}_{x} * R_{error} * R_{init} * K^{-1} * x = 0
\end{equation}
Having:
\begin{equation} \label{eq:leftRelative}
\begin{array}{lcl}
h_{'}^{T} &=& {x}_{'}^{T} * K^{-T} \\
h &=& R_{init} * K^{-1} * x \\
G &=& \begin{bmatrix}T\end{bmatrix}_{x} * R_{error} \\
\end{array}
\end{equation}
With such notation one can notice that:
\begin{equation} \label{eq:alternativeEnhancedEquation}
{h}_{'}^{T} * G * h = 0
\end{equation}
which resembles the already known fundamental (Equation \ref{eq:fundamntalEquation}) and essential equations (\ref{eq:essentialEquation}). Naturally, $h_{'}$ and h both are expressed in homogenous coordinates. Tt follows from the analysis that G has 6DOF: 3 due to an unknown translation and another 3 due to an unknown correction angles (created by rotation error matrix decomposition). Theoretically, such matrix can be resolved for instance by both 5 and 8-point algorithms. Therefore the standard fundamental and essential equation solvers can be used in order to retrieve both $\begin{bmatrix}T\end{bmatrix}_{x}$ and $R_{error}$.
The finally estimated $R_{error}$ and calculated $R_{init}$ has to be multiplied in order for the new rotation estimation of R (Equation \ref{eq:Rerror}) to be retrieved.
Pursuant to Appendix 6 ''Multiple View Geometry in Computer Vision''(A6.9.1 \cite{HartleyMultipleView}), the use of Rodrigues parametrisation for small angles (and noise in initial rotation matrices estimations can be expressed by small angles) the rotation matrix, and thus $R_{error}$, equals approximately to:
\begin{equation} \label{eq:rodiguesError}
R_{error} \cong 
\begin{bmatrix*}[c]
    1   &  -w_{z}&  w_{y}\\ 
 w_{z}  &    1   & -w_{x}\\
-w_{y}  &  w_{x} &   1
\end{bmatrix*}
\end{equation} 
Such a criterion with a special matrix design can be used when decomposing G to resolve some ambiguity in choosing the proper solution. The standard four solution ambiguity with two possible rotations and translations can be reduced to two possible translation calculations. The concept described constitutes a basis of the implemented, enhanced 8-point and 5-point algorithms.

\subsection{Alternative 3-point algorithm for finding the translation}
Following the equation \ref{eq:alternativeEnhancedEquation} it can be stated that:
\begin{equation} \label{eq:alternative3point}
{x}_{'}^{T} * K^{-T} * \begin{bmatrix*}[c]
 0 & -t_{z} & t_{y}\\
 t_{z} & 0 & -t_{x}\\
-t_{y} & t_{x} & 0 
\end{bmatrix*} * R * K^{-1} * x = 0
\end{equation}
Having:
\begin{equation} \label{eq:leftRelative}
\begin{array}{lcl}
h_{'}^{T} &=& {x}_{'}^{T} * K^{-T} \\
h &=& K^{-1} * x \\
\end{array}
\end{equation}
and 
\begin{equation} \label{eq:alternative3point}
\begin{bmatrix*}[c]
h_{'1} & h_{'2} & h_{'3}
\end{bmatrix*}
* \begin{bmatrix*}[c]
 0 & -t_{z} & t_{y}\\
 t_{z} & 0 & -t_{x}\\
-t_{y} & t_{x} & 0 
\end{bmatrix*} 
* \begin{bmatrix*}[c]
h_{1} \\
h_{2} \\
h_{3}
\end{bmatrix*}
= 0
\end{equation}
and multiplying it one receives the following:
\begin{equation} \label{eq:alternative3point}
h_{1}*h_{'2}*t_{z} - h_{1}*h_{'3}*t_{y} - h_{2}*h_{'1}*t_{z} + h_{2}*h_{'3}*t_{x} + h_{3}*h_{'1}*t_{y} - h_{3}*h_{'2}*t_{x}
= 0
\end{equation}
what can be grouped:
\begin{equation}
t_{x} * (h_{2}*h_{'3} - h_{3}*h_{'2}) + t_{y} * (h_{3}*h_{'1} - h_{1}*h_{'3}) + t_{z} * (h_{1}*h_{'2} - h_{2}*h_{'1}) = 0
\end{equation}
and rewritten as:
\begin{equation} \label{eq:translation3point}
\begin{bmatrix*}[c]
t_{x} &
t_{y} &
t_{z}
\end{bmatrix*} * \begin{bmatrix*}[c]
(h_{2}*h_{'3} - h_{3}*h_{'2}) \\ 
(h_{3}*h_{'1} - h_{1}*h_{'3}) \\
(h_{1}*h_{'2} - h_{2}*h_{'1}) 
\end{bmatrix*} 
= 0
\end{equation}
then solved for instance with SVD with only three points. This is a truly fast way of estimating translation for the reconstructed images. However, in such situation the overall accuracy strictly depends on the precise measurements of camera orientation.

\section{Known rotations \& translations}
Where accurate rotations and translations of cameras are known, no additional pose calculations are needed. Such a situation is interesting, since everything needed for corresponding points triangulation is already known. However, mobile sensor data  measurements are very noisy. In that case Bundle Adjustment can be used in order to refine the measured calculated camera positions and the final 3D cloud reconstruction.


% ---------------------------------------------------------------------------
%: ----------------------- end of thesis sub-document ------------------------
% ---------------------------------------------------------------------------

