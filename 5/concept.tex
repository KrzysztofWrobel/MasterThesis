% this file is called up by thesis.tex
% content in this file will be fed into the main document

%: ----------------------- name of chapter  -------------------------
\chapter{Concept} % top level followed by section, subsection
As indicated in similar research it's very attractive to use additional data to enhance reconstruction and reduce ambiguity in finding correct solution of 3D reconstruction. Additional camera or model information help to implement faster, more stable and robust algorithms. This thesis will show how prior knowledge of rotation or translation acquired via mobile sensor fusion can be used to enhance process of 3D reconstruction from series images. When it comes to relaying on hand-held smartphones, collected sensor data are very noisy. This thesis, how even noisy informations can be used in struction reconstraction processes. Initially only camera rotation estimation was supposed to be used in the scope of this mater thesis. However first trials of reconstruction proved to be not sufficient enough and additional rotation error matrix estimations were proposed.
From analysis of theory and related works it seems that both epipolar equations and pose estimation techniques can be improved with additional rotation and translation information data.  Author of this thesis proposes environment, where user can decide what type of stargy to use.
\section{Requirements}
Proposed methodology needs as the input series of images with additional information about position of the camera - euclidan rotation and optionally translation. Usage of smartphone is actually not necessary. Any camera with SensorFusioned accelerometer and gyroscope(magnotometer is actually optional and as discussed in [TODO] has its advantages and disadvantages) capable of rotation and translation estimation can be used. Internal camera parameters need to be calculated before reconstruction process is started. Additional sensor data doesn't have to be very accurate. Noisy external camera parameters stil can be successfully used in order to enhance reconstruction process.
\section{Enhancing epipolar geometry equations with initial rotation matrix}
Initial pair reconstruction step is very important and needs to be accurate to let other images calculate relative position on basis of initially reconstructed 3D cloud points.
Taking standard fundamental geometry equation and relative camera based system ($P = \begin{bmatrix}I |0\end{bmatrix}, P' = \begin{bmatrix}R|t\end{bmatrix}$) we can note that:
\begin{equation} \label{eq:relativeFundamntal}
{x}_{'}^{T} * K^{-T} * \begin{bmatrix}T\end{bmatrix}_{x} * R * K^{-1} * x = 0
\end{equation}
It is can also be written that:
\begin{equation} \label{eq:skewTranslation}
\begin{bmatrix}T\end{bmatrix}_{x} = 
\begin{bmatrix*}[c]
 0 & -t_{z} & t_{y}\\
 t_{z} & 0 & -t_{x}\\
-t_{y} & t_{x} & 0 
\end{bmatrix*} 
where T = \begin{bmatrix}t_{x},t_{y},t_{z}\end{bmatrix}
\end{equation}
As we were discussing rotation can be distorted with noise. This can be written as:
\begin{equation} \label{eq:Rerror}
R = R_{error} * R_{init} 
\end{equation}
where $R_{init}$ is initial rotation matrix constructed from measured angles and $R_{error}$ is rotation error matrix.
Looking at this from different point of view \ref{eq:Rerror} can be interpreted as multipling two rotations matrix: 
One estimated, but close to local optimum initial rotation matrix and second one, which is responsible for correction of noise error. 
Basic idea of algorithm proposed in this thesis is instead of relative whole rotation matrix calculation, which can be acquired from Essential matrix SVD decomposition, only rotation $R_{error}$ can be estimated. In the end \ref{eq:relativeFundamntal} can be rewritten in form:
\begin{equation} \label{eq:relativeFundamntalEnhanced}
{x}_{'}^{T} * K^{-T} * \begin{bmatrix}T\end{bmatrix}_{x} * R_{error} * R_{init} * K^{-1} * x = 0
\end{equation}
Having:
\begin{equation} \label{eq:leftRelative}
\begin{array}{lcl}
h_{'}^{T} &=& {x}_{'}^{T} * K^{-T} \\
h &=& R_{init} * K^{-1} * x \\
G &=& \begin{bmatrix}T\end{bmatrix}_{x} * R_{error} \\
\end{array}
\end{equation}
With such notation one can notice that:
\begin{equation} \label{eq:alternativeEnhancedEquation}
{h}_{'}^{T} * G * h = 0
\end{equation}
which resembles already known fundamental(\ref:{eq:fundamntalEquation}) and essential equations (\ref{eq:essentialEquation}). Of cource $h_{'}$ and h both are expressed in homogenous coordinates in such situation. From analysis it is known that G has 6DOF: 3 due to unknown translation and another 3 due to unknown correction angles(created by rotation error matrx decomposition). From theory such matrix can be resolved for instance by both 5 and 8-point algorithms. So basicly standard fundamental and essential equation solvers can be used in order to retrieve both $\begin{bmatrix}T\end{bmatrix}_{x}$ and $R_{error}$.
In the end estimated $R_{error}$ and calculated $R_{init}$ has to be multiplied to retrieve new rotation estimation of R (\ref{eq:Rerror}).
From Appendix 6 "Multiple View Geometry in Computer Vision"(A6.9.1 \cite{HartleyMultipleView}) using Rodigues parametrization, when angles are small(and noise in initial rotation matrices estimations can be expresed by small angles) rotation matrix and thus $R_{error}$ as well is more or less equals to:
\begin{equation} \label{eq:rodiguesError}
R_{error} \cong 
\begin{bmatrix*}[c]
    1   &  -w_{z}&  w_{y}\\ 
 w_{z}  &    1   & -w_{x}\\
-w_{y}  &  w_{x} &   1
\end{bmatrix*}
\end{equation} 
Such criterium with special matrix design can be used when decomposing G to resolve some ambiguity in choosing proper solution. From standard 4 solution ambiguity with 2 possible rotations and translations, it can bre reduced to 2 possible translation calculations. Described concept is basis of implemented enhanced 8-point and 5-point algorithms

\subsection{Alternative 3-point algorithm for translation finding}
Starting \ref{eq:alternativeEnhancedEquation} it can be written that:
\begin{equation} \label{eq:alternative3point}
{x}_{'}^{T} * K^{-T} * \begin{bmatrix*}[c]
 0 & -t_{z} & t_{y}\\
 t_{z} & 0 & -t_{x}\\
-t_{y} & t_{x} & 0 
\end{bmatrix*} * R * K^{-1} * x = 0
\end{equation}
Having:
\begin{equation} \label{eq:leftRelative}
\begin{array}{lcl}
h_{'}^{T} &=& {x}_{'}^{T} * K^{-T} \\
h &=& K^{-1} * x \\
\end{array}
\end{equation}
and 
\begin{equation} \label{eq:alternative3point}
\begin{bmatrix*}[c]
h_{'1} & h_{'2} & h_{'3}
\end{bmatrix*}
* \begin{bmatrix*}[c]
 0 & -t_{z} & t_{y}\\
 t_{z} & 0 & -t_{x}\\
-t_{y} & t_{x} & 0 
\end{bmatrix*} 
* \begin{bmatrix*}[c]
h_{1} \\
h_{2} \\
h_{3}
\end{bmatrix*}
= 0
\end{equation}
and multiplying it we will end up with
\begin{equation} \label{eq:alternative3point}
h_{1}*h_{'2}*t_{z} - h_{1}*h_{'3}*t_{y} - h_{2}*h_{'1}*t_{z} + h_{2}*h_{'3}*t_{x} + h_{3}*h_{'1}*t_{y} - h_{3}*h_{'2}*t_{x}
= 0
\end{equation}
what can be grouped:
\begin{equation}
t_{x} * (h_{2}*h_{'3} - h_{3}*h_{'2}) + t_{y} * (h_{3}*h_{'1} - h_{1}*h_{'3}) + t_{z} * (h_{1}*h_{'2} - h_{2}*h_{'1}) = 0
\end{equation}
rewritten as:
\begin{equation} \label{eq:translation3point}
\begin{bmatrix*}[c]
t_{x} &
t_{y} &
t_{z}
\end{bmatrix*} * \begin{bmatrix*}[c]
(h_{2}*h_{'3} - h_{3}*h_{'2}) \\ 
(h_{3}*h_{'1} - h_{1}*h_{'3}) \\
(h_{1}*h_{'2} - h_{2}*h_{'1}) 
\end{bmatrix*} 
= 0
\end{equation}
and solved for instance with SVD with only 3 points. This is very fast way of translation estimation in reconstracted images. However in such situation overall accuracy strictly depends on precise measuerments of camera orientation.
\section{Pose estimation}
One of the main goal was to make more accurate and faster version of reconstruction algorithm. That is way relative pose estimation techniques were used to enrich models with additional points. In general, this approach produces less outliers than homography merging techniques. This is also allows to keep scale among reconstructed images. For any point in image, which has corresponding 3D point following condition is kept:
\begin{equation} \label{eq:projectionEquation}
 x = P * X
\end{equation}
where x is image point expressed in homogenous coordinates (x , y , 1) and X homogenous 3D  point (X , Y , Z , 1). 
Projection matrix of the camera design looks as follow: 
\begin{equation} \label{eq:projectionEquation}
 P = K * \begin{bmatrix}R\mid t\end{bmatrix}
\end{equation}
\subsection{Rotation enhancements}
Using similar thinking to initial pair reconstruction enhancements it can be noted that:
\begin{equation} \label{eq:projectionRotError1}
\begin{array}{rcl}
 x & = & K * \begin{bmatrix}Rinit + dR\mid t\end{bmatrix} * X \\
 x & = & K * \begin{bmatrix}Rinit\mid 0\end{bmatrix} * X + K * \begin{bmatrix}dR\mid t\end{bmatrix} * X \\
 x - K * \begin{bmatrix}Rinit\mid 0\end{bmatrix} & = & K * \begin{bmatrix}dR\mid t\end{bmatrix} * X
\end{array}
\end{equation}
Substituting $x_{m} = x - K * \begin{bmatrix}Rinit\mid 0\end{bmatrix}$ we get: 
\begin{equation} \label{eq:projectionRotError2}
x_{m} = K * \begin{bmatrix}dR\mid t\end{bmatrix} * X
\end{equation}
This can be solved using normal PNP calculating algorithms. Using rotation as initial solution for pose estimation can be used in order to focus only on rotation error and translation estimation.
\subsection{Rotation \& translation enhancements}
Similar to \ref{eq:projectionRotError1}:
\begin{equation} \label{eq:projectionRotError3}
\begin{array}{rcl}
 x & = & K * \begin{bmatrix}Rinit + dR\mid Tinit + dt\end{bmatrix} * X \\
 x & = & K * \begin{bmatrix}Rinit\mid Tinit\end{bmatrix} * X + K * \begin{bmatrix}dR\mid dt\end{bmatrix} * X \\
 x - K * \begin{bmatrix}Rinit\mid Tinit\end{bmatrix} & = & K * \begin{bmatrix}dR\mid dt\end{bmatrix} * X
\end{array}
\end{equation}
end in the end by Substituting $x_{n} = x - K * \begin{bmatrix}Rinit\mid Tinit\end{bmatrix}$ we get: 
\begin{equation} \label{eq:projectionRotError4}
x_{n} = K * \begin{bmatrix}dR\mid dt\end{bmatrix} * X
\end{equation}
This situation can also be solved using normal PNP[TODO reference] calculation algorithm. Using rotation and translation as initial solutions for pose estimation can be used in order to focus only on rotation error and translation error estimation.
\section{Known rotations \& translations}
In situation were accurate rotations and translations of cameras are known no aditional pose calculations are needed. Such situation is interesting, because everything needed for corresponding points triangulation is already known. However in mobile sensor data, such measurements are very noisy. However Bundle Adjustment can be used in order to refine measured calculated camera positions and final 3D cloud reconstruction.
\section{Reconstruction process strategy}
Finally all methods described in this section can be combined in different reconstruction strategies. In terms of initialization of 3D cloud point can be made using: 
%TODO zrobić lepszy styl
\begin{enumerate} 
\item \textbf{Known rotatations and translations}, which theoritcally allows on up-to-metrical reconstruction
\item \textbf{Known rotations}, where translation is estimated with alternative 3-point algorithm
\item \textbf{Noisy rotations}, where enhanced 8-point fundamental or 5-point essential algorithms are used in order to calculate rotation error and relative translation 
\item \textbf{Unknown external camera parameters}, where standard 8-point fundamental or 5-point essential algorithms are used in order to calculate Rotation and relative translation
\end{enumerate}
In terms of Pose Estimation following methodologies can be used:
\begin{enumerate}
\item \textbf{Known rotatation and translations}, where no additional calculations are required and up-to-metrical model can be acquired
\item \textbf{Initial rotation}, where relative translation needs to be calculated
\item \textbf{Nosy rotation and translation}, where both rotation and translation error needs to be calculated
\item \textbf{Unknown external camera parameters}, where standard pose estimation has to be used
\end{enumerate}

% ---------------------------------------------------------------------------
%: ----------------------- end of thesis sub-document ------------------------
% ---------------------------------------------------------------------------

